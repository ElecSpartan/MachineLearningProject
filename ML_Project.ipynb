{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Description\n",
        "The data used in this project will help to identify whether a person is going to recover from \n",
        "coronavirus symptoms or not based on some pre-defined standard symptoms. These symptoms are \n",
        "based on guidelines given by the World Health Organization (WHO).\n",
        "This dataset has daily level information on the number of affected cases, deaths and recovery from \n",
        "2019 novel coronavirus. Please note that this is a time series data and so the number of cases on \n",
        "any given day is the cumulative number.\n",
        "The data is available from 22 Jan, 2020. Data is in “data.csv”.\n",
        "The dataset contains 14 major variables that will be having an impact on whether someone has \n",
        "recovered or not, the description of each variable are as follows,\n",
        "1. Country: where the person resides\n",
        "2. Location: which part in the Country\n",
        "3. Age: Classification of the age group for each person, based on WHO Age Group Standard\n",
        "4. Gender: Male or Female \n",
        "5. Visited_Wuhan: whether the person has visited Wuhan, China or not\n",
        "6. From_Wuhan: whether the person is from Wuhan, China or not\n",
        "7. Symptoms: there are six families of symptoms that are coded in six fields.\n",
        "13. Time_before_symptoms_appear: \n",
        "14. Result: death (1) or recovered (0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First we will import the main libraries for the whole Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load and Visualize the Data... since it is of a high dimensional we will just see the table of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     location country gender   age vis_wuhan from_wuhan symptom1 symptom2  \\\n",
            "0.0       104       8      1  66.0         1          0       14       31   \n",
            "1.0       101       8      0  56.0         0          1       14       31   \n",
            "2.0       137       8      1  46.0         0          1       14       31   \n",
            "3.0       116       8      0  60.0         1          0       14       31   \n",
            "4.0       116       8      1  58.0         0          0       14       31   \n",
            "5.0        23       8      0  44.0         0          1       14       31   \n",
            "6.0       105       8      1  34.0         0          1       14       31   \n",
            "7.0        13       8      1  37.0         1          0       14       31   \n",
            "8.0        13       8      1  39.0         1          0       14       31   \n",
            "9.0        13       8      1  56.0         1          0       14       31   \n",
            "10.0       13       8      0  18.0         1          0       14       31   \n",
            "\n",
            "     symptom3 symptom4 symptom5 symptom6 diff_sym_hos result  \n",
            "0.0        19       12        3        1            8      1  \n",
            "1.0        19       12        3        1            0      0  \n",
            "2.0        19       12        3        1           13      0  \n",
            "3.0        19       12        3        1            0      0  \n",
            "4.0        19       12        3        1            0      0  \n",
            "5.0        19       12        3        1            0      0  \n",
            "6.0        19       12        3        1            0      0  \n",
            "7.0        19       12        3        1            6      0  \n",
            "8.0        19       12        3        1            5      0  \n",
            "9.0        19       12        3        1            4      0  \n",
            "10.0       19       12        3        1            1      0  \n"
          ]
        }
      ],
      "source": [
        "names = ['location',\"country\",\"gender\",\"age\",\"vis_wuhan\",\"from_wuhan\",\"symptom1\",\n",
        "        \"symptom2\",\"symptom3\",\"symptom4\",\"symptom5\",\"symptom6\",\"diff_sym_hos\",\"result\"]\n",
        "df = pd.read_csv(\"data.csv\",header=None,names=names)\n",
        "print(df.loc[0:10]) #visualising first 11 rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### divide the data into three partitions: training, validation, and testing\n",
        "#### used the conventional 70% training 15% validation and 15% testing parititioning with randomness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(864, 14)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "print(df.shape)\n",
        "X = df.drop(columns=['result'])  #dropping the column of the target\n",
        "Y = df['result']\n",
        "\n",
        "\n",
        "train_ratio = 0.7\n",
        "validation_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Split the data using train_test_split with randomness\n",
        "XTrain, X_temp, YTrain, Y_temp = train_test_split(X, Y, test_size=1 - train_ratio, random_state=42)\n",
        "XValidation, XTest, YValidation, YTest = train_test_split(\n",
        "    X_temp, Y_temp, test_size=test_ratio / (validation_ratio + test_ratio), random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## First Classification method is KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
